{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "yB70dodBzbTu"
   },
   "outputs": [],
   "source": [
    "# Import Required Packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import math\n",
    "import operator\n",
    "import random\n",
    "import scipy.optimize as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ckDxLYAt-zF0"
   },
   "source": [
    "# 1. Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ekWNmbgJ1EQK",
    "outputId": "0a1203a6-5af8-4a55-ab95-7167a2acda21"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    }
   ],
   "source": [
    "# Set a Random Seed\n",
    "random.seed(1234)\n",
    "# Import Data\n",
    "data = pd.read_csv('https://raw.githubusercontent.com/propublica/compas-analysis/master/compas-scores-two-years.csv')\n",
    "\n",
    "# Data Cleaning \n",
    "data = data[(data['race']=='African-American') | (data['race']=='Caucasian')]\n",
    "data = data[data.columns[data.isna().mean() < 0.5]]\n",
    "data = data.drop(columns = ['id','name','first', 'last', 'dob','age_cat', 'compas_screening_date','v_screening_date','in_custody',\n",
    "                            'out_custody', 'c_offense_date', 'c_days_from_compas' ,'c_jail_in','c_jail_out','c_case_number',\n",
    "                            'days_b_screening_arrest','screening_date','c_charge_desc','start','end','type_of_assessment','v_type_of_assessment',\n",
    "                            'juv_fel_count','juv_misd_count','juv_other_count','event'])\n",
    "\n",
    "# Data Relabel\n",
    "data['race'].loc[data['race'] == 'African-American'] = 0\n",
    "data['race'].loc[data['race'] == 'Caucasian'] = 1\n",
    "data['c_charge_degree'] = LabelEncoder().fit_transform(data['c_charge_degree'])\n",
    "data['score_text'] = LabelEncoder().fit_transform(data['score_text'])\n",
    "data['v_score_text'] = LabelEncoder().fit_transform(data['v_score_text'])\n",
    "data['sex'] = LabelEncoder().fit_transform(data['sex'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "6XBAjemSaVaf"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Training & Testing Split\n",
    "training, testing = train_test_split(data, test_size=0.2, random_state=1234)\n",
    "training_sensitive = training.loc[data['race'] == 1, data.columns !='two_year_recid']\n",
    "testing_sensitive = testing.loc[data['race'] == 1, data.columns !='two_year_recid']\n",
    "training_nonsensitive = training.loc[data['race'] == 0, data.columns !='two_year_recid']\n",
    "testing_nonsensitive = testing.loc[data['race'] == 0, data.columns !='two_year_recid']\n",
    "ytrain_sensitive = training.loc[data['race'] == 1, data.columns =='two_year_recid']\n",
    "ytrain_nonsensitive = training.loc[data['race'] == 0, data.columns =='two_year_recid']\n",
    "ytesting_sensitive = testing.loc[data['race'] == 1, data.columns =='two_year_recid']\n",
    "ytesting_nonsensitive = testing.loc[data['race'] == 0, data.columns =='two_year_recid']\n",
    "\n",
    "# Converting to Array\n",
    "training_sensitive = np.array(training_sensitive)\n",
    "training_nonsensitive = np.array(training_nonsensitive)\n",
    "testing_sensitive = np.array(testing_sensitive)\n",
    "testing_nonsensitive = np.array(testing_nonsensitive)\n",
    "ytrain_nonsensitive = np.array(ytrain_nonsensitive)\n",
    "ytrain_sensitive = np.array(ytrain_sensitive)\n",
    "ytesting_sensitive = np.array(ytesting_sensitive)\n",
    "ytesting_nonsensitive = np.array(ytesting_nonsensitive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iVoYA02E_OEf"
   },
   "source": [
    "# 2. Algorithm Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "oJyvVoZ2y28K"
   },
   "outputs": [],
   "source": [
    "# Helper Function for LFR\n",
    "\n",
    "def distances(X, v, alpha, N, P, k):\n",
    "    dists = np.zeros((N, P))\n",
    "    for i in range(N):\n",
    "        for p in range(P):\n",
    "            for j in range(k):    \n",
    "                dists[i, j] += (X[i, p] - v[j, p]) * (X[i, p] - v[j, p]) * alpha[p]\n",
    "    return dists\n",
    "\n",
    "def M_nk(dists, N, k):\n",
    "    M_nk = np.zeros((N, k))\n",
    "    exp = np.zeros((N, k))\n",
    "    denom = np.zeros(N)\n",
    "    for i in range(N):\n",
    "        for j in range(k):\n",
    "            exp[i, j] = np.exp(-1 * dists[i, j])\n",
    "            denom[i] += exp[i, j]\n",
    "        for j in range(k):\n",
    "            if denom[i]:\n",
    "                M_nk[i, j] = exp[i, j] / denom[i]\n",
    "            else:\n",
    "                M_nk[i, j] = exp[i, j] / 1e-6\n",
    "    return M_nk\n",
    "  \n",
    "def M_k(M_nk, N, k):\n",
    "    M_k = np.zeros(k)\n",
    "    for j in range(k):\n",
    "        for i in range(N):\n",
    "            M_k[j] += M_nk[i, j]\n",
    "        M_k[j] /= N\n",
    "    return M_k\n",
    "      \n",
    "\n",
    "def x_n_hat(X, M_nk, v, N, P, k):\n",
    "    x_n_hat = np.zeros((N, P))\n",
    "    L_x = 0.0\n",
    "    for i in range(N):\n",
    "        for p in range(P):\n",
    "            for j in range(k):\n",
    "                x_n_hat[i, p] += M_nk[i, j] * v[j, p]\n",
    "            L_x += (X[i, p] - x_n_hat[i, p]) * (X[i, p] - x_n_hat[i, p])\n",
    "    return x_n_hat, L_x\n",
    "\n",
    "\n",
    "def yhat(M_nk, y, w, N, k):\n",
    "    yhat = np.zeros(N)\n",
    "    L_y = 0.0\n",
    "    for i in range(N):\n",
    "        for j in range(k):\n",
    "            yhat[i] += M_nk[i, j] * w[j]\n",
    "        yhat[i] = 1e-6 if yhat[i] <= 0 else yhat[i]\n",
    "        yhat[i] = 0.999 if yhat[i] >= 1 else yhat[i]\n",
    "        L_y += -1 * y[i] * np.log(yhat[i]) - (1.0 - y[i]) * np.log(1.0 - yhat[i])\n",
    "    return yhat, L_y\n",
    "\n",
    "\n",
    "def LFR(params, data_sensitive, data_nonsensitive, y_sensitive, \n",
    "        y_nonsensitive,  k=10, A_x = 1e-4, A_y = 0.1, A_z = 1000, results=0):\n",
    "    \n",
    "    LFR.iters += 1 \n",
    "    Ns, P = data_sensitive.shape\n",
    "    Nns, _ = data_nonsensitive.shape\n",
    "    \n",
    "    alpha0 = params[:P]\n",
    "    alpha1 = params[P : 2 * P]\n",
    "    w = params[2 * P : (2 * P) + k]\n",
    "    v = np.matrix(params[(2 * P) + k:]).reshape((k, P))\n",
    "        \n",
    "    dists_sensitive = distances(data_sensitive, v, alpha1, Ns, P, k)\n",
    "    dists_nonsensitive = distances(data_nonsensitive, v, alpha0, Nns, P, k)\n",
    "\n",
    "    M_nk_sensitive = M_nk(dists_sensitive, Ns, k)\n",
    "    M_nk_nonsensitive = M_nk(dists_nonsensitive, Nns, k)\n",
    "    \n",
    "    M_k_sensitive = M_k(M_nk_sensitive, Ns, k)\n",
    "    M_k_nonsensitive = M_k(M_nk_nonsensitive, Nns, k)\n",
    "    \n",
    "    L_z = 0.0\n",
    "    for j in range(k):\n",
    "        L_z += abs(M_k_sensitive[j] - M_k_nonsensitive[j])\n",
    "\n",
    "    x_n_hat_sensitive, L_x1 = x_n_hat(data_sensitive, M_nk_sensitive, v, Ns, P, k)\n",
    "    x_n_hat_nonsensitive, L_x2 = x_n_hat(data_nonsensitive, M_nk_nonsensitive, v, Nns, P, k)\n",
    "    L_x = L_x1 + L_x2\n",
    "\n",
    "    yhat_sensitive, L_y1 = yhat(M_nk_sensitive, y_sensitive, w, Ns, k)\n",
    "    yhat_nonsensitive, L_y2 = yhat(M_nk_nonsensitive, y_nonsensitive, w, Nns, k)\n",
    "    L_y = L_y1 + L_y2\n",
    "\n",
    "    criterion = A_x * L_x + A_y * L_y + A_z * L_z\n",
    "\n",
    "    if LFR.iters % 250 == 0:\n",
    "        print(LFR.iters, criterion)\n",
    "      \n",
    "    if results:\n",
    "        return yhat_sensitive, yhat_nonsensitive, M_nk_sensitive, M_nk_nonsensitive\n",
    "    else:\n",
    "        return criterion\n",
    "LFR.iters = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "XFLM6385JlJU"
   },
   "outputs": [],
   "source": [
    "k = 10\n",
    "rez = np.random.uniform(size=training_sensitive.shape[1] * 2 + k + training_sensitive.shape[1] * k)\n",
    "\n",
    "bnd = []\n",
    "for i, k2 in enumerate(rez):\n",
    "    if i < training_sensitive.shape[1] * 2 or i >= training_sensitive.shape[1] * 2 + k:\n",
    "        bnd.append((None, None))\n",
    "    else:\n",
    "        bnd.append((0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sa2TV29s-DeP",
    "outputId": "bdd5696a-8743-422f-d11e-1e81b13d5b57"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1831.22692953])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LFR(rez, training_sensitive, training_nonsensitive, ytrain_sensitive, \n",
    "    ytrain_nonsensitive, k, 1e-4, 0.1, 1000, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XLLySlNj1ewU",
    "outputId": "8b0b1a11-a2df-4301-d065-50ec6b42b331"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250 [1939.91176207]\n",
      "500 [1640.27065909]\n",
      "750 [1639.83908276]\n",
      "1000 [1642.92002674]\n",
      "1250 [1639.74024451]\n",
      "1500 [1639.96148832]\n",
      "1750 [1640.11085966]\n",
      "2000 [1639.65001765]\n",
      "2250 [1639.64238655]\n",
      "2500 [1639.63541975]\n",
      "2750 [1639.55319808]\n"
     ]
    }
   ],
   "source": [
    "# Optimization Process\n",
    "LFR.iters = 0\n",
    "rez = optim.fmin_l_bfgs_b(LFR, x0=rez,\n",
    "                          args=(training_sensitive, training_nonsensitive, \n",
    "                                ytrain_sensitive, ytrain_nonsensitive, k, 1e-4,\n",
    "                                0.1, 1000, 0),\n",
    "                          bounds = bnd, approx_grad=True, maxfun = 1500, maxiter = 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G0iSNJXvIKCj",
    "outputId": "23247193-4b17-44ff-9fc6-c93131326246"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.70091108e-01, 2.95578493e-01, 4.02644714e-01, 5.84007899e-01,\n",
       "       8.45709474e-01, 4.53519524e-01, 3.93401377e-01, 2.76994307e-02,\n",
       "       4.48697452e-01, 4.28644863e-01, 2.24176661e-01, 2.76653586e-01,\n",
       "       7.64609888e-01, 4.60166201e-02, 3.17763350e-01, 4.65585835e-01,\n",
       "       7.15328919e-01, 6.71084273e-01, 4.89153797e-01, 3.62430093e-01,\n",
       "       3.74555654e-01, 2.43800856e-01, 4.91611255e-01, 5.03546225e-01,\n",
       "       9.26721327e-01, 7.63483876e-01, 9.74476896e-01, 3.98249910e-04,\n",
       "       6.27381053e-01, 7.67667339e-01, 8.38144640e-02, 3.31638863e-01,\n",
       "       6.08474306e-01, 4.38187712e-01, 5.90013940e-01, 2.96009793e-01,\n",
       "       3.85191510e-01, 4.61810466e-01, 8.40535958e-01, 1.28944016e-01,\n",
       "       2.06800754e-01, 2.02462377e-01, 1.00535352e-01, 3.10745592e-01,\n",
       "       9.69214048e-01, 5.44370229e-02, 4.37725272e-01, 7.41628138e-01,\n",
       "       3.15780033e-01, 3.83167708e-01, 7.78999389e-01, 8.66701914e-01,\n",
       "       1.17426276e-01, 5.09855786e-01, 7.62845655e-01, 3.60444685e-01,\n",
       "       1.10393794e-03, 1.39422375e-01, 9.37070949e-01, 8.77644054e-01,\n",
       "       6.46511279e-03, 6.03564172e-02, 5.76188060e-01, 6.67306295e-01,\n",
       "       4.93775515e-01, 1.10990318e-01, 4.01574507e-02, 7.82897657e-01,\n",
       "       2.11832602e-01, 8.07801750e-02, 1.67736663e-01, 8.70494854e-02,\n",
       "       6.23381447e-01, 6.48570914e-01, 7.31638374e-01, 1.25121554e-01,\n",
       "       4.06627963e-01, 7.25553623e-02, 2.85356262e-01, 5.42595000e-01,\n",
       "       1.59224695e-01, 2.16676704e-01, 7.75080035e-01, 6.83495356e-01,\n",
       "       8.93450393e-01, 8.54115158e-02, 1.63615225e-01, 8.24807103e-01,\n",
       "       4.06209851e-01, 1.54049179e-01, 7.69977945e-02, 6.30832148e-01,\n",
       "       6.21363849e-01, 6.59155904e-01, 2.15769784e-01, 9.39535564e-01,\n",
       "       6.10593216e-01, 5.81643261e-02, 8.51675857e-01, 7.84293842e-01,\n",
       "       1.17028253e-01, 5.03171495e-02, 1.10303550e+00, 3.24087391e-01,\n",
       "       3.69622675e-01, 8.52089380e-01, 9.93398783e-01, 7.64578443e-03,\n",
       "       2.49056986e-01, 2.54673644e-01, 3.04365826e-01, 2.26385988e-01,\n",
       "       8.75704161e-01, 8.32076050e-01, 5.96870455e-02, 4.59827165e-01,\n",
       "       6.80198768e-01, 4.13128484e-01, 3.31551303e-01, 7.01439576e-01,\n",
       "       1.05677955e-01, 2.63826916e-01, 8.90145081e-01, 4.29201492e-01,\n",
       "       7.42756576e-01, 5.16606564e-01, 5.77706960e-01, 2.37015026e-01,\n",
       "       3.16659472e-02, 1.61388563e-01, 9.72699053e-01, 4.77506457e-01,\n",
       "       3.24279981e-02, 4.91622043e-01, 3.39817124e-01, 9.32533806e-01,\n",
       "       3.28923152e-01, 7.32547910e-02, 9.38363166e-03, 3.70017631e-01,\n",
       "       9.11131699e-01, 2.86810466e-01, 5.76008301e-01, 3.20165460e-01,\n",
       "       9.89643470e-01, 9.68879949e-01, 5.92104910e-01, 9.76350945e-01,\n",
       "       1.69921633e-01, 9.70223743e-02, 5.40547584e-01, 2.34766284e-01,\n",
       "       5.47802041e-01, 8.05173804e-01, 6.92225074e-01, 5.15707512e-01,\n",
       "       7.55034447e-01, 5.22670029e-02, 2.09619573e-01, 2.06340995e-01,\n",
       "       9.49715564e-01, 2.29138765e-01, 6.98979371e-01, 4.80926449e-02,\n",
       "       9.24294670e-01, 1.54337426e-01])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the optimization result\n",
    "\n",
    "result=rez[0]\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PhvwFMiAS7w_"
   },
   "source": [
    "# 3. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "AmhwvQvCl3-v"
   },
   "outputs": [],
   "source": [
    "# Euclidean Distance Function\n",
    "def euclideanDistance(instance1, instance2):\n",
    "    distance = 0\n",
    "    for x in range(len(instance1)):\n",
    "        distance += pow((instance1[x] - instance2[x]), 2)\n",
    "    return math.sqrt(distance)\n",
    "\n",
    "\n",
    "# KNN Function\n",
    "def getKNeighbors(trainingSet, testInstance, k):\n",
    "    distances = []\n",
    "    for x in range(len(trainingSet)):\n",
    "        dist = euclideanDistance(testInstance, trainingSet[x])\n",
    "        distances.append(dist)\n",
    "    distances = np.array(distances)\n",
    "    neighbors = distances.argsort()[0:k]\n",
    "    return neighbors\n",
    "\n",
    "# Individual Fairness Evaluation\n",
    "def individualfair(data, yhat):\n",
    "    length = len(yhat)\n",
    "    result = 0\n",
    "    for i in range(length):\n",
    "        neighbors = getKNeighbors(np.concatenate((data[:i],data[i+1:]), axis = 0), data[i], 3)\n",
    "        result += abs(yhat[i] - yhat[neighbors[0]] -  yhat[neighbors[1]] -  yhat[neighbors[2]])\n",
    "\n",
    "    result = 1 - result/(length * 3)\n",
    "    return result\n",
    "\n",
    "\n",
    "# Write A Evaluation Function\n",
    "def LFR_metric(params, data_sensitive, data_nonsensitive, y_sensitive, \n",
    "        y_nonsensitive,  k=10, A_x = 1e-4, A_y = 0.1, A_z = 1000):\n",
    "    \n",
    "    Ns, P = data_sensitive.shape\n",
    "    Nns, _ = data_nonsensitive.shape\n",
    "    \n",
    "    alpha0 = params[:P]\n",
    "    alpha1 = params[P : 2 * P]\n",
    "    w = params[2 * P : (2 * P) + k]\n",
    "    v = np.matrix(params[(2 * P) + k:]).reshape((k, P))\n",
    "        \n",
    "    dists_sensitive = distances(data_sensitive, v, alpha1, Ns, P, k)\n",
    "    dists_nonsensitive = distances(data_nonsensitive, v, alpha0, Nns, P, k)\n",
    "\n",
    "    M_nk_sensitive = M_nk(dists_sensitive, Ns, k)\n",
    "    M_nk_nonsensitive = M_nk(dists_nonsensitive, Nns, k)\n",
    "    \n",
    "    M_k_sensitive = M_k(M_nk_sensitive, Ns, k)\n",
    "    M_k_nonsensitive = M_k(M_nk_nonsensitive, Nns, k)\n",
    "    \n",
    "    L_z = 0.0\n",
    "    for j in range(k):\n",
    "        L_z += abs(M_k_sensitive[j] - M_k_nonsensitive[j])\n",
    "\n",
    "    x_n_hat_sensitive, L_x1 = x_n_hat(data_sensitive, M_nk_sensitive, v, Ns, P, k)\n",
    "    x_n_hat_nonsensitive, L_x2 = x_n_hat(data_nonsensitive, M_nk_nonsensitive, v, Nns, P, k)\n",
    "    L_x = L_x1 + L_x2\n",
    "\n",
    "    yhat_sensitive, L_y1 = yhat(M_nk_sensitive, y_sensitive, w, Ns, k)\n",
    "    yhat_nonsensitive, L_y2 = yhat(M_nk_nonsensitive, y_nonsensitive, w, Nns, k)\n",
    "    L_y = L_y1 + L_y2\n",
    "\n",
    "    data_all = np.concatenate((data_sensitive, data_nonsensitive), axis = 0)\n",
    "    yhat_all = np.concatenate((yhat_sensitive, yhat_nonsensitive), axis = 0)\n",
    "    individual_fairness = individualfair(data_all, yhat_all)\n",
    "\n",
    "    criterion = A_x * L_x + A_y * L_y + A_z * L_z\n",
    "    \n",
    "    sen_acc = accuracy_score(y_sensitive, (yhat_sensitive >= 0.5))\n",
    "    nonsen_acc = accuracy_score(y_nonsensitive, (yhat_nonsensitive >= 0.5))\n",
    "    tot_acc = (Ns * sen_acc + Nns * nonsen_acc) / (Ns + Nns)\n",
    "\n",
    "    calibration = abs(sen_acc - nonsen_acc)\n",
    "\n",
    "    return criterion, sen_acc, nonsen_acc, tot_acc, calibration, L_x, L_y, L_z, individual_fairness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "8KZnhYEVj8gM"
   },
   "outputs": [],
   "source": [
    "metrics = LFR_metric(result, testing_sensitive, testing_nonsensitive, ytesting_sensitive, ytesting_nonsensitive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "__dGs7fd7WXL",
    "outputId": "d18e67eb-a55c-4f8f-a0b7-842f6e81b7f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: [484.34520659], Sensitive Accuracy: 0.6068548387096774, Nonsensitive Accuracy: 0.4891008174386921,  Total Accuracy: 0.5365853658536586,  Clibration: 0.11775402127098528, Individual Fairness: 0.8118169264545848\n"
     ]
    }
   ],
   "source": [
    "print(\"LOSS: {}, Sensitive Accuracy: {}, Nonsensitive Accuracy: {},  Total Accuracy: {},  Clibration: {}, Individual Fairness: {}\".format(\n",
    "            metrics[0], metrics[1], metrics[2], metrics[3], metrics[4], metrics[8]))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LFR.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
